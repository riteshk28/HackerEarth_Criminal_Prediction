{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritesh.kankonkar\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "#For some Statistics\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, recall_score, matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERID</th>\n",
       "      <th>IFATHER</th>\n",
       "      <th>NRCH17_2</th>\n",
       "      <th>IRHHSIZ2</th>\n",
       "      <th>IIHHSIZ2</th>\n",
       "      <th>IRKI17_2</th>\n",
       "      <th>IIKI17_2</th>\n",
       "      <th>IRHH65_2</th>\n",
       "      <th>IIHH65_2</th>\n",
       "      <th>PRXRETRY</th>\n",
       "      <th>PRXYDATA</th>\n",
       "      <th>MEDICARE</th>\n",
       "      <th>CAIDCHIP</th>\n",
       "      <th>CHAMPUS</th>\n",
       "      <th>PRVHLTIN</th>\n",
       "      <th>GRPHLTIN</th>\n",
       "      <th>HLTINNOS</th>\n",
       "      <th>HLCNOTYR</th>\n",
       "      <th>HLCNOTMO</th>\n",
       "      <th>HLCLAST</th>\n",
       "      <th>HLLOSRSN</th>\n",
       "      <th>HLNVCOST</th>\n",
       "      <th>HLNVOFFR</th>\n",
       "      <th>HLNVREF</th>\n",
       "      <th>HLNVNEED</th>\n",
       "      <th>HLNVSOR</th>\n",
       "      <th>IRMCDCHP</th>\n",
       "      <th>IIMCDCHP</th>\n",
       "      <th>IRMEDICR</th>\n",
       "      <th>IIMEDICR</th>\n",
       "      <th>IRCHMPUS</th>\n",
       "      <th>IICHMPUS</th>\n",
       "      <th>IRPRVHLT</th>\n",
       "      <th>IIPRVHLT</th>\n",
       "      <th>IROTHHLT</th>\n",
       "      <th>IIOTHHLT</th>\n",
       "      <th>HLCALLFG</th>\n",
       "      <th>HLCALL99</th>\n",
       "      <th>ANYHLTI2</th>\n",
       "      <th>IRINSUR4</th>\n",
       "      <th>IIINSUR4</th>\n",
       "      <th>OTHINS</th>\n",
       "      <th>CELLNOTCL</th>\n",
       "      <th>CELLWRKNG</th>\n",
       "      <th>IRFAMSOC</th>\n",
       "      <th>IIFAMSOC</th>\n",
       "      <th>IRFAMSSI</th>\n",
       "      <th>IIFAMSSI</th>\n",
       "      <th>IRFSTAMP</th>\n",
       "      <th>IIFSTAMP</th>\n",
       "      <th>IRFAMPMT</th>\n",
       "      <th>IIFAMPMT</th>\n",
       "      <th>IRFAMSVC</th>\n",
       "      <th>IIFAMSVC</th>\n",
       "      <th>IRWELMOS</th>\n",
       "      <th>IIWELMOS</th>\n",
       "      <th>IRPINC3</th>\n",
       "      <th>IRFAMIN3</th>\n",
       "      <th>IIPINC3</th>\n",
       "      <th>IIFAMIN3</th>\n",
       "      <th>GOVTPROG</th>\n",
       "      <th>POVERTY3</th>\n",
       "      <th>TOOLONG</th>\n",
       "      <th>TROUBUND</th>\n",
       "      <th>PDEN10</th>\n",
       "      <th>COUTYP2</th>\n",
       "      <th>MAIIN102</th>\n",
       "      <th>AIIND102</th>\n",
       "      <th>ANALWT_C</th>\n",
       "      <th>VESTR</th>\n",
       "      <th>VEREP</th>\n",
       "      <th>Criminal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25095143</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3884.805998</td>\n",
       "      <td>40026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13005143</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1627.108106</td>\n",
       "      <td>40015</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67415143</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4344.957980</td>\n",
       "      <td>40024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70925143</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>792.521931</td>\n",
       "      <td>40027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75235143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1518.118526</td>\n",
       "      <td>40001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
       "0  25095143        4         2         4         1         3         1   \n",
       "1  13005143        4         1         3         1         2         1   \n",
       "2  67415143        4         1         2         1         2         1   \n",
       "3  70925143        4         0         2         1         1         1   \n",
       "4  75235143        1         0         6         1         4         1   \n",
       "\n",
       "   IRHH65_2  IIHH65_2  PRXRETRY  PRXYDATA  MEDICARE  CAIDCHIP  CHAMPUS  \\\n",
       "0         1         1        99        99         2         1        2   \n",
       "1         1         1        99        99         2         2        2   \n",
       "2         1         1        99        99         2         1        2   \n",
       "3         1         1        99        99         2         2        2   \n",
       "4         1         1        99         1         2         1        2   \n",
       "\n",
       "   PRVHLTIN  GRPHLTIN  HLTINNOS  HLCNOTYR  HLCNOTMO  HLCLAST  HLLOSRSN  \\\n",
       "0         2        99        99         2        99       99        99   \n",
       "1         1         1        99         2        99       99        99   \n",
       "2         2        99        99         2        99       99        99   \n",
       "3         1         1        99         2        99       99        99   \n",
       "4         2        99        99         2        99       99        99   \n",
       "\n",
       "   HLNVCOST  HLNVOFFR  HLNVREF  HLNVNEED  HLNVSOR  IRMCDCHP  IIMCDCHP  \\\n",
       "0        99        99       99        99       99         1         1   \n",
       "1        99        99       99        99       99         2         1   \n",
       "2        99        99       99        99       99         1         1   \n",
       "3        99        99       99        99       99         2         1   \n",
       "4        99        99       99        99       99         1         1   \n",
       "\n",
       "   IRMEDICR  IIMEDICR  IRCHMPUS  IICHMPUS  IRPRVHLT  IIPRVHLT  IROTHHLT  \\\n",
       "0         2         1         2         1         2         1        99   \n",
       "1         2         1         2         1         1         1        99   \n",
       "2         2         1         2         1         2         1        99   \n",
       "3         2         1         2         1         1         1        99   \n",
       "4         2         1         2         1         2         1        99   \n",
       "\n",
       "   IIOTHHLT  HLCALLFG  HLCALL99  ANYHLTI2  IRINSUR4  IIINSUR4  OTHINS  \\\n",
       "0         9        98        98         1         1         1       2   \n",
       "1         9        98        98         1         1         1       2   \n",
       "2         9        98        98         1         1         1       2   \n",
       "3         9        98        98         1         1         1       2   \n",
       "4         9        98        98         1         1         1       2   \n",
       "\n",
       "   CELLNOTCL  CELLWRKNG  IRFAMSOC  IIFAMSOC  IRFAMSSI  IIFAMSSI  IRFSTAMP  \\\n",
       "0          1          1         2         1         2         1         1   \n",
       "1          1          1         2         1         2         1         1   \n",
       "2          2          1         1         1         2         1         1   \n",
       "3          1          1         2         1         2         1         2   \n",
       "4          2          1         2         1         2         1         1   \n",
       "\n",
       "   IIFSTAMP  IRFAMPMT  IIFAMPMT  IRFAMSVC  IIFAMSVC  IRWELMOS  IIWELMOS  \\\n",
       "0         1         2         1         2         1        99         9   \n",
       "1         1         2         1         2         1        99         9   \n",
       "2         1         2         1         2         1        99         9   \n",
       "3         1         2         1         2         1        99         9   \n",
       "4         1         2         1         1         1         1         1   \n",
       "\n",
       "   IRPINC3  IRFAMIN3  IIPINC3  IIFAMIN3  GOVTPROG  POVERTY3  TOOLONG  \\\n",
       "0        1         4        1         1         1         2        1   \n",
       "1        1         1        1         1         1         1        2   \n",
       "2        2         2        1         1         1         1        2   \n",
       "3        7         7        1         1         2         3        2   \n",
       "4        1         2        1         1         1         1        2   \n",
       "\n",
       "   TROUBUND  PDEN10  COUTYP2  MAIIN102  AIIND102     ANALWT_C  VESTR  VEREP  \\\n",
       "0         2       1        1         2         2  3884.805998  40026      1   \n",
       "1         2       2        3         2         2  1627.108106  40015      2   \n",
       "2         2       2        3         2         2  4344.957980  40024      1   \n",
       "3         2       1        1         2         2   792.521931  40027      1   \n",
       "4         2       2        2         2         2  1518.118526  40001      2   \n",
       "\n",
       "   Criminal  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's import the set\n",
    "pd.set_option('display.max_columns', 80)\n",
    "df = pd.read_csv('criminal_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random  over samplinng\n",
      "0    42543\n",
      "1     9000\n",
      "Name: Criminal, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15a13198>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13fe3ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the data is quite clean and needs minimal preprocessing.\n",
    "#class imbalance is of 6% which greatly affects the model performance and hence we will try to over sample the data\n",
    "# from 6% we will raise class 1 to almost 20%. Too much data could be overfitted and too less could be generalised as class 0\n",
    "\n",
    "#2 dataframes divided by classes\n",
    "df_class_0 = df[df['Criminal'] == 0]\n",
    "df_class_1 = df[df['Criminal'] == 1]\n",
    "\n",
    "#create a over sample of class 1\n",
    "df_class_1_over = df_class_1.sample(9000, replace=True)\n",
    "\n",
    "df_over = pd.concat([df_class_1_over, df_class_0], axis=0)\n",
    "\n",
    "print ('Random  over samplinng')\n",
    "print (df_over['Criminal'].value_counts())\n",
    "\n",
    "sns.countplot(df_over['Criminal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since this is a final model, we will be fitting all of the data and evaluation can be done on the online evaluation.\n",
    "#Earlier modelling have been done with trian and error with train_test_split.\n",
    "#There is no sense in fitting the model on the entire dataset and then evaluate it against the same sample dataset, however, it can be done for understanding how well have we performed.\n",
    "\n",
    "X = df_over.drop(['PERID', 'Criminal'], axis=1)\n",
    "\n",
    "y = df_over['Criminal']\n",
    "\n",
    "#sc = StandardScaler()\n",
    "#X = sc.fit_transform(X)\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will be using Gradient Boosting method as it has proved to be ferforming well in the past trial and errors.\n",
    "\n",
    "#gb = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "#gb.fit(X, y)\n",
    "\n",
    "#ada_boost = AdaBoostClassifier()\n",
    "#ada_boost.fit(X, y)\n",
    "\n",
    "gboost = GradientBoostingClassifier(max_depth=3, n_estimators=250)\n",
    "gboost.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#xpred = xgb.predict(X_test)\n",
    "#matthews_corrcoef(y_test, xpred)\n",
    "\n",
    "#ada_pred = ada_boost.predict(X_test)\n",
    "#matthews_corrcoef(y_test, ada_pred)\n",
    "\n",
    "#gpred = gboost.predict(X_test)\n",
    "#matthews_corrcoef(y_test, gpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 74 and input n_features is 72 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b2f4145538fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#test = sc.fit_transform(test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m#test_pred = (test_pred > 0.6)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ritesh.kankonkar\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1530\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         \"\"\"\n\u001b[1;32m-> 1532\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1533\u001b[0m         \u001b[0mdecisions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_score_to_decision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecisions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ritesh.kankonkar\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1485\u001b[0m         \"\"\"\n\u001b[0;32m   1486\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1487\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1489\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ritesh.kankonkar\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         \u001b[1;31m# for use in inner loop, not raveling the output in single-class case,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \u001b[1;31m# not doing input validation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1130\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[0mpredict_stages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ritesh.kankonkar\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36m_init_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[1;34m\"\"\"Check input and compute prediction of ``init``. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m             raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n",
      "\u001b[1;32mC:\\Users\\ritesh.kankonkar\\AppData\\Local\\Continuum\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\tree\\tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    382\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 74 and input n_features is 72 "
     ]
    }
   ],
   "source": [
    "#predicting and saving our results\n",
    "\n",
    "test = pd.read_csv('criminal_test.csv')\n",
    "PERID = test.PERID\n",
    "test = test.drop(['PERID'], axis=1)\n",
    "\n",
    "new1 = test.drop(['ANALWT_C', 'VESTR', 'NRCH17_2', 'IRHHSIZ2', 'IIHHSIZ2', 'IRKI17_2', 'IIKI17_2', 'IRHH65_2', \n",
    "                  'IIHH65_2', 'IRMCDCHP', 'IIMCDCHP', 'IRMEDICR', 'IIMEDICR', 'IRCHMPUS', 'IICHMPUS', 'IRPRVHLT', 'IIPRVHLT'], axis=1)\n",
    "\n",
    "drop1 = test[['ANALWT_C', 'VESTR']]\n",
    "#drop = sc.fit_transform(drop)\n",
    "\n",
    "\n",
    "extras1 = test[['ANALWT_C', 'VESTR', 'NRCH17_2', 'IRHHSIZ2', 'IIHHSIZ2', 'IRKI17_2', 'IIKI17_2', 'IRHH65_2', \n",
    "                'IIHH65_2', 'IRMCDCHP', 'IIMCDCHP', 'IRMEDICR', 'IIMEDICR', 'IRCHMPUS', 'IICHMPUS', 'IRPRVHLT', 'IIPRVHLT']]\n",
    "\n",
    "new1 = pd.get_dummies(new, drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "test = pd.concat((new1, drop1, extras1), axis=1)\n",
    "\n",
    "#test = sc.fit_transform(test)\n",
    "\n",
    "test_pred = gboost.predict(test)\n",
    "#test_pred = (test_pred > 0.6)\n",
    "test_pred = pd.DataFrame(test_pred)\n",
    "\n",
    "\n",
    "data = pd.concat([PERID, test_pred], axis=1)\n",
    "\n",
    "data.to_csv('gboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
